{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 2 -  Regularization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Os1OWmQUTuT",
        "colab_type": "text"
      },
      "source": [
        "# Task 2 - Regularization\n",
        "\n",
        "The following regularization techniques were applied\n",
        "\n",
        "* L1L2 Regularization of kernels\n",
        "* Dropout network\n",
        "\n",
        "The plots can be found below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXLAGYAayHny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL.Image\n",
        "import IPython.display as display\n",
        "import warnings"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJh1Dcs6yVFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5de93b23-602a-4ac2-cf53-46009c607344"
      },
      "source": [
        "cifar10 = keras.datasets.cifar10\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, y_train.astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=60000).batch(128)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, y_test.astype(np.int32))).batch(64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTEvsTx89UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "opt = keras.optimizers.Adam(lr = learning_rate)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "no_classes = 10\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "val_split = 0.2\n",
        "Dropout_Factor = 0.25\n",
        "img_width, img_height, num_channels = 32,32,3\n",
        "input_shape = (img_width, img_height, num_channels)\n",
        "\n",
        "logdir = \"logs/Adam_0.001\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_h-r0ZY9D5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,kernel_initializer = 'random_normal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L7ieDIS9ITj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bd6b932-098b-480a-88e9-64eab2470aa1"
      },
      "source": [
        "model.compile(optimizer=opt,loss=loss_fn,metrics=[\"accuracy\"])\n",
        "plain_history = model.fit(data,batch_size = batch_size,epochs = 100,validation_data = (test_data),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/391 [..............................] - ETA: 15s - loss: 2.3009 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0127s vs `on_train_batch_end` time: 0.0639s). Check your callbacks.\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6429 - accuracy: 0.3961 - val_loss: 1.3460 - val_accuracy: 0.5088\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2449 - accuracy: 0.5525 - val_loss: 1.2337 - val_accuracy: 0.5647\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.0874 - accuracy: 0.6150 - val_loss: 1.0519 - val_accuracy: 0.6267\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9605 - accuracy: 0.6623 - val_loss: 1.0125 - val_accuracy: 0.6495\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8754 - accuracy: 0.6928 - val_loss: 0.9529 - val_accuracy: 0.6712\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8036 - accuracy: 0.7195 - val_loss: 0.8785 - val_accuracy: 0.6938\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7358 - accuracy: 0.7426 - val_loss: 0.8636 - val_accuracy: 0.7011\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6850 - accuracy: 0.7608 - val_loss: 0.8598 - val_accuracy: 0.7061\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6291 - accuracy: 0.7799 - val_loss: 0.8467 - val_accuracy: 0.7126\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5878 - accuracy: 0.7938 - val_loss: 0.8902 - val_accuracy: 0.7005\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5359 - accuracy: 0.8119 - val_loss: 0.8565 - val_accuracy: 0.7186\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4905 - accuracy: 0.8264 - val_loss: 0.8541 - val_accuracy: 0.7228\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4406 - accuracy: 0.8445 - val_loss: 0.8789 - val_accuracy: 0.7223\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4006 - accuracy: 0.8583 - val_loss: 0.9452 - val_accuracy: 0.7123\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3709 - accuracy: 0.8691 - val_loss: 0.9349 - val_accuracy: 0.7263\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3288 - accuracy: 0.8830 - val_loss: 0.9777 - val_accuracy: 0.7252\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2920 - accuracy: 0.8964 - val_loss: 1.0514 - val_accuracy: 0.7159\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2669 - accuracy: 0.9052 - val_loss: 1.0755 - val_accuracy: 0.7237\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2311 - accuracy: 0.9178 - val_loss: 1.1260 - val_accuracy: 0.7231\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2001 - accuracy: 0.9281 - val_loss: 1.2366 - val_accuracy: 0.7137\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1864 - accuracy: 0.9337 - val_loss: 1.2504 - val_accuracy: 0.7136\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1856 - accuracy: 0.9344 - val_loss: 1.2883 - val_accuracy: 0.7202\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1485 - accuracy: 0.9466 - val_loss: 1.4743 - val_accuracy: 0.7062\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1498 - accuracy: 0.9460 - val_loss: 1.4762 - val_accuracy: 0.7140\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1404 - accuracy: 0.9496 - val_loss: 1.5041 - val_accuracy: 0.7159\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1201 - accuracy: 0.9576 - val_loss: 1.5995 - val_accuracy: 0.7127\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1227 - accuracy: 0.9556 - val_loss: 1.5725 - val_accuracy: 0.7128\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1073 - accuracy: 0.9604 - val_loss: 1.7806 - val_accuracy: 0.7103\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1125 - accuracy: 0.9595 - val_loss: 1.7740 - val_accuracy: 0.7084\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1033 - accuracy: 0.9638 - val_loss: 1.7083 - val_accuracy: 0.7133\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0910 - accuracy: 0.9687 - val_loss: 1.7966 - val_accuracy: 0.7053\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0967 - accuracy: 0.9664 - val_loss: 1.8910 - val_accuracy: 0.7141\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0928 - accuracy: 0.9675 - val_loss: 1.8860 - val_accuracy: 0.7096\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 1.9199 - val_accuracy: 0.7011\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0866 - accuracy: 0.9691 - val_loss: 1.9684 - val_accuracy: 0.7122\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0823 - accuracy: 0.9709 - val_loss: 2.0042 - val_accuracy: 0.7053\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0863 - accuracy: 0.9700 - val_loss: 2.0966 - val_accuracy: 0.7122\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 2.0307 - val_accuracy: 0.7142\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0768 - accuracy: 0.9742 - val_loss: 2.0436 - val_accuracy: 0.7126\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0718 - accuracy: 0.9760 - val_loss: 2.1544 - val_accuracy: 0.7173\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 2.1994 - val_accuracy: 0.7031\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0914 - accuracy: 0.9687 - val_loss: 2.0600 - val_accuracy: 0.7157\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0656 - accuracy: 0.9772 - val_loss: 2.1239 - val_accuracy: 0.7102\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0568 - accuracy: 0.9799 - val_loss: 2.2051 - val_accuracy: 0.7065\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0759 - accuracy: 0.9737 - val_loss: 2.2126 - val_accuracy: 0.7076\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0624 - accuracy: 0.9785 - val_loss: 2.3131 - val_accuracy: 0.7060\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0623 - accuracy: 0.9785 - val_loss: 2.3268 - val_accuracy: 0.7091\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 2.3149 - val_accuracy: 0.7095\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0714 - accuracy: 0.9761 - val_loss: 2.2273 - val_accuracy: 0.7076\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 2.3406 - val_accuracy: 0.7038\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0762 - accuracy: 0.9752 - val_loss: 2.2951 - val_accuracy: 0.7054\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0525 - accuracy: 0.9816 - val_loss: 2.3145 - val_accuracy: 0.7125\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 2.4102 - val_accuracy: 0.6998\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 2.4282 - val_accuracy: 0.7121\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 2.4604 - val_accuracy: 0.7046\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 2.4593 - val_accuracy: 0.7104\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 2.5266 - val_accuracy: 0.7093\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0643 - accuracy: 0.9784 - val_loss: 2.4174 - val_accuracy: 0.7116\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 2.4515 - val_accuracy: 0.7029\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0600 - accuracy: 0.9797 - val_loss: 2.4294 - val_accuracy: 0.7072\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 2.4724 - val_accuracy: 0.7090\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0532 - accuracy: 0.9819 - val_loss: 2.6521 - val_accuracy: 0.6917\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 2.4825 - val_accuracy: 0.6992\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 2.6175 - val_accuracy: 0.6983\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 2.5311 - val_accuracy: 0.7068\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 2.6709 - val_accuracy: 0.7076\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 2.7251 - val_accuracy: 0.7009\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0480 - accuracy: 0.9840 - val_loss: 2.6644 - val_accuracy: 0.6955\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 2.6357 - val_accuracy: 0.6975\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0506 - accuracy: 0.9830 - val_loss: 2.5714 - val_accuracy: 0.7145\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 2.5644 - val_accuracy: 0.7084\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0459 - accuracy: 0.9845 - val_loss: 2.5001 - val_accuracy: 0.7093\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 2.6627 - val_accuracy: 0.7051\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 2.6540 - val_accuracy: 0.7066\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0448 - accuracy: 0.9847 - val_loss: 2.6870 - val_accuracy: 0.7009\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 2.6802 - val_accuracy: 0.7037\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 2.8333 - val_accuracy: 0.7007\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0568 - accuracy: 0.9813 - val_loss: 2.7184 - val_accuracy: 0.7094\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 2.7139 - val_accuracy: 0.7069\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0459 - accuracy: 0.9850 - val_loss: 2.6154 - val_accuracy: 0.7083\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0424 - accuracy: 0.9851 - val_loss: 2.9232 - val_accuracy: 0.6980\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0506 - accuracy: 0.9834 - val_loss: 2.7311 - val_accuracy: 0.7055\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 2.8163 - val_accuracy: 0.7089\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0524 - accuracy: 0.9837 - val_loss: 2.7115 - val_accuracy: 0.7073\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 2.7243 - val_accuracy: 0.7127\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0480 - accuracy: 0.9839 - val_loss: 2.8175 - val_accuracy: 0.6967\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 2.6997 - val_accuracy: 0.7002\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 2.7670 - val_accuracy: 0.7030\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 2.8185 - val_accuracy: 0.6995\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 2.8072 - val_accuracy: 0.7030\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 2.7072 - val_accuracy: 0.7039\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 2.8036 - val_accuracy: 0.7125\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 2.8826 - val_accuracy: 0.7044\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 2.9255 - val_accuracy: 0.6985\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 2.7592 - val_accuracy: 0.7076\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 2.7769 - val_accuracy: 0.7104\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 2.9046 - val_accuracy: 0.7053\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 2.8528 - val_accuracy: 0.7090\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 3.0067 - val_accuracy: 0.7062\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0518 - accuracy: 0.9841 - val_loss: 2.9281 - val_accuracy: 0.7055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qshGSzg_sxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_with_regularizer = Sequential()\n",
        "model_with_regularizer.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,kernel_initializer = 'random_normal',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model_with_regularizer.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_with_regularizer.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model_with_regularizer.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model_with_regularizer.add(Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model_with_regularizer.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model_with_regularizer.add(Flatten())\n",
        "model_with_regularizer.add(Dense(256, activation='relu',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model_with_regularizer.add(Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model_with_regularizer.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "learning_rate = 0.001\n",
        "opt = keras.optimizers.Adam(lr = learning_rate)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "no_classes = 10\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "val_split = 0.2\n",
        "Dropout_Factor = 0.25\n",
        "img_width, img_height, num_channels = 32,32,3\n",
        "input_shape = (img_width, img_height, num_channels)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuXM40OKAYna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a93ad88-2f7a-4c4f-e48d-373ca279cd47"
      },
      "source": [
        "logdir = \"logs/L1 L2 regularizers\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "model_with_regularizer.compile(optimizer=opt,loss=loss_fn,metrics=[\"accuracy\"])\n",
        "regulaizer_history = model_with_regularizer.fit(data,batch_size = batch_size,epochs = 100,validation_data = (test_data),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/391 [..............................] - ETA: 17s - loss: 2.4950 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0777s). Check your callbacks.\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7726 - accuracy: 0.3770 - val_loss: 1.4978 - val_accuracy: 0.4959\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3945 - accuracy: 0.5297 - val_loss: 1.3040 - val_accuracy: 0.5682\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2337 - accuracy: 0.5975 - val_loss: 1.2884 - val_accuracy: 0.5903\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.1212 - accuracy: 0.6407 - val_loss: 1.1337 - val_accuracy: 0.6471\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.0317 - accuracy: 0.6774 - val_loss: 1.0625 - val_accuracy: 0.6717\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.9591 - accuracy: 0.7032 - val_loss: 1.0221 - val_accuracy: 0.6867\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.9071 - accuracy: 0.7257 - val_loss: 1.0033 - val_accuracy: 0.6972\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8537 - accuracy: 0.7468 - val_loss: 1.0201 - val_accuracy: 0.6919\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8040 - accuracy: 0.7630 - val_loss: 0.9841 - val_accuracy: 0.7085\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7591 - accuracy: 0.7820 - val_loss: 0.9748 - val_accuracy: 0.7128\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7292 - accuracy: 0.7921 - val_loss: 1.0013 - val_accuracy: 0.7093\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6881 - accuracy: 0.8100 - val_loss: 1.0255 - val_accuracy: 0.7132\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6608 - accuracy: 0.8202 - val_loss: 1.0001 - val_accuracy: 0.7199\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6258 - accuracy: 0.8352 - val_loss: 0.9892 - val_accuracy: 0.7296\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5973 - accuracy: 0.8453 - val_loss: 1.0555 - val_accuracy: 0.7132\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5713 - accuracy: 0.8548 - val_loss: 1.0339 - val_accuracy: 0.7291\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5405 - accuracy: 0.8688 - val_loss: 1.0754 - val_accuracy: 0.7224\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5188 - accuracy: 0.8757 - val_loss: 1.1142 - val_accuracy: 0.7237\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4961 - accuracy: 0.8859 - val_loss: 1.1712 - val_accuracy: 0.7207\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4724 - accuracy: 0.8965 - val_loss: 1.1577 - val_accuracy: 0.7213\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4624 - accuracy: 0.9004 - val_loss: 1.2786 - val_accuracy: 0.7132\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4354 - accuracy: 0.9119 - val_loss: 1.2856 - val_accuracy: 0.7176\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4267 - accuracy: 0.9149 - val_loss: 1.2770 - val_accuracy: 0.7231\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4067 - accuracy: 0.9239 - val_loss: 1.3451 - val_accuracy: 0.7148\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3973 - accuracy: 0.9267 - val_loss: 1.3298 - val_accuracy: 0.7180\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3899 - accuracy: 0.9296 - val_loss: 1.4065 - val_accuracy: 0.7177\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3797 - accuracy: 0.9351 - val_loss: 1.4958 - val_accuracy: 0.7159\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3728 - accuracy: 0.9381 - val_loss: 1.4510 - val_accuracy: 0.7161\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3505 - accuracy: 0.9482 - val_loss: 1.5111 - val_accuracy: 0.7175\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3576 - accuracy: 0.9455 - val_loss: 1.5509 - val_accuracy: 0.7184\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3707 - accuracy: 0.9411 - val_loss: 1.5164 - val_accuracy: 0.7159\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3446 - accuracy: 0.9518 - val_loss: 1.5470 - val_accuracy: 0.7144\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3332 - accuracy: 0.9564 - val_loss: 1.6751 - val_accuracy: 0.7164\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3495 - accuracy: 0.9516 - val_loss: 1.6192 - val_accuracy: 0.7190\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3433 - accuracy: 0.9543 - val_loss: 1.6260 - val_accuracy: 0.7149\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3291 - accuracy: 0.9602 - val_loss: 1.6385 - val_accuracy: 0.7191\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3332 - accuracy: 0.9577 - val_loss: 1.6896 - val_accuracy: 0.7154\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3259 - accuracy: 0.9621 - val_loss: 1.7219 - val_accuracy: 0.7140\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3351 - accuracy: 0.9583 - val_loss: 1.7997 - val_accuracy: 0.7041\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3284 - accuracy: 0.9615 - val_loss: 1.7613 - val_accuracy: 0.7156\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3211 - accuracy: 0.9642 - val_loss: 1.7566 - val_accuracy: 0.7203\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3171 - accuracy: 0.9657 - val_loss: 1.7098 - val_accuracy: 0.7147\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3137 - accuracy: 0.9667 - val_loss: 1.7362 - val_accuracy: 0.7175\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3273 - accuracy: 0.9619 - val_loss: 1.8112 - val_accuracy: 0.7200\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3187 - accuracy: 0.9662 - val_loss: 1.7450 - val_accuracy: 0.7174\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3300 - accuracy: 0.9613 - val_loss: 1.7864 - val_accuracy: 0.7189\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3045 - accuracy: 0.9716 - val_loss: 1.8381 - val_accuracy: 0.7154\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3129 - accuracy: 0.9684 - val_loss: 1.8211 - val_accuracy: 0.7099\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3237 - accuracy: 0.9649 - val_loss: 1.7539 - val_accuracy: 0.7188\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3231 - accuracy: 0.9656 - val_loss: 1.7956 - val_accuracy: 0.7115\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3085 - accuracy: 0.9708 - val_loss: 1.8418 - val_accuracy: 0.7186\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3051 - accuracy: 0.9716 - val_loss: 1.8643 - val_accuracy: 0.7119\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3110 - accuracy: 0.9696 - val_loss: 1.8521 - val_accuracy: 0.7112\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3168 - accuracy: 0.9673 - val_loss: 1.8938 - val_accuracy: 0.7130\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3118 - accuracy: 0.9688 - val_loss: 1.9079 - val_accuracy: 0.7143\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3217 - accuracy: 0.9664 - val_loss: 1.8622 - val_accuracy: 0.7089\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3153 - accuracy: 0.9673 - val_loss: 1.8102 - val_accuracy: 0.7225\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2977 - accuracy: 0.9745 - val_loss: 1.9620 - val_accuracy: 0.7107\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3042 - accuracy: 0.9724 - val_loss: 1.8543 - val_accuracy: 0.7062\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2978 - accuracy: 0.9755 - val_loss: 1.8829 - val_accuracy: 0.7166\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3245 - accuracy: 0.9656 - val_loss: 1.8764 - val_accuracy: 0.7124\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3113 - accuracy: 0.9694 - val_loss: 1.9671 - val_accuracy: 0.7113\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3067 - accuracy: 0.9725 - val_loss: 1.8604 - val_accuracy: 0.7209\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3121 - accuracy: 0.9703 - val_loss: 1.8447 - val_accuracy: 0.7094\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3096 - accuracy: 0.9713 - val_loss: 1.9113 - val_accuracy: 0.7128\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3012 - accuracy: 0.9742 - val_loss: 1.9186 - val_accuracy: 0.7244\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3046 - accuracy: 0.9737 - val_loss: 1.8657 - val_accuracy: 0.7136\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3159 - accuracy: 0.9687 - val_loss: 1.9401 - val_accuracy: 0.7167\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2986 - accuracy: 0.9751 - val_loss: 1.9355 - val_accuracy: 0.7261\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2910 - accuracy: 0.9772 - val_loss: 1.9185 - val_accuracy: 0.7078\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3079 - accuracy: 0.9719 - val_loss: 1.9059 - val_accuracy: 0.7086\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3154 - accuracy: 0.9696 - val_loss: 1.8469 - val_accuracy: 0.7197\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3081 - accuracy: 0.9714 - val_loss: 1.9118 - val_accuracy: 0.7146\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2955 - accuracy: 0.9754 - val_loss: 1.9751 - val_accuracy: 0.7158\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3018 - accuracy: 0.9738 - val_loss: 2.0572 - val_accuracy: 0.7064\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3034 - accuracy: 0.9728 - val_loss: 1.9240 - val_accuracy: 0.7181\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2993 - accuracy: 0.9750 - val_loss: 1.8967 - val_accuracy: 0.7129\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3030 - accuracy: 0.9737 - val_loss: 1.9591 - val_accuracy: 0.7142\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3018 - accuracy: 0.9743 - val_loss: 1.8638 - val_accuracy: 0.7083\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3065 - accuracy: 0.9723 - val_loss: 1.9295 - val_accuracy: 0.7107\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3021 - accuracy: 0.9733 - val_loss: 2.0802 - val_accuracy: 0.7100\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3045 - accuracy: 0.9725 - val_loss: 1.9105 - val_accuracy: 0.7223\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3023 - accuracy: 0.9741 - val_loss: 1.9439 - val_accuracy: 0.7080\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2923 - accuracy: 0.9764 - val_loss: 1.9256 - val_accuracy: 0.7098\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2953 - accuracy: 0.9759 - val_loss: 1.9339 - val_accuracy: 0.7105\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2987 - accuracy: 0.9738 - val_loss: 1.9051 - val_accuracy: 0.7152\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2949 - accuracy: 0.9758 - val_loss: 1.9011 - val_accuracy: 0.7162\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3048 - accuracy: 0.9721 - val_loss: 1.9316 - val_accuracy: 0.7161\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2888 - accuracy: 0.9780 - val_loss: 1.9172 - val_accuracy: 0.7140\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3003 - accuracy: 0.9737 - val_loss: 2.0447 - val_accuracy: 0.7096\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2908 - accuracy: 0.9777 - val_loss: 1.9413 - val_accuracy: 0.7168\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2857 - accuracy: 0.9796 - val_loss: 2.0068 - val_accuracy: 0.7020\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3181 - accuracy: 0.9677 - val_loss: 1.8959 - val_accuracy: 0.7180\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2978 - accuracy: 0.9749 - val_loss: 1.9569 - val_accuracy: 0.7120\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2995 - accuracy: 0.9747 - val_loss: 1.8973 - val_accuracy: 0.7110\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2950 - accuracy: 0.9748 - val_loss: 1.9295 - val_accuracy: 0.7160\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2886 - accuracy: 0.9785 - val_loss: 2.0177 - val_accuracy: 0.7067\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2929 - accuracy: 0.9763 - val_loss: 2.0958 - val_accuracy: 0.7112\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3017 - accuracy: 0.9728 - val_loss: 1.9427 - val_accuracy: 0.7055\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2880 - accuracy: 0.9785 - val_loss: 1.9832 - val_accuracy: 0.7187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Km_MPSGt-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ece6fa57-c7e7-496f-ba6e-1a1c689fa42b"
      },
      "source": [
        "learning_rate = 0.001\n",
        "opt = keras.optimizers.Adam(lr = learning_rate)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "no_classes = 10\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "val_split = 0.2\n",
        "Dropout_Factor = 0.25\n",
        "img_width, img_height, num_channels = 32,32,3\n",
        "input_shape = (img_width, img_height, num_channels)\n",
        "\n",
        "Dropout_model = Sequential()\n",
        "Dropout_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,kernel_initializer = 'random_normal'))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal'))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Dropout(0.25))\n",
        "Dropout_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal'))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Dropout(0.25))\n",
        "Dropout_model.add(Flatten())\n",
        "Dropout_model.add(Dense(256, activation='relu'))\n",
        "Dropout_model.add(Dense(128, activation='relu'))\n",
        "Dropout_model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "logdir = \"logs/dropouts\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "Dropout_model.compile(optimizer=opt,loss=loss_fn,metrics=[\"accuracy\"])\n",
        "Dropout_history = Dropout_model.fit(data,batch_size = batch_size,epochs = 100,validation_data = (test_data),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/391 [..............................] - ETA: 20s - loss: 2.3072 - accuracy: 0.0898WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0941s). Check your callbacks.\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.7099 - accuracy: 0.3664 - val_loss: 1.4900 - val_accuracy: 0.4673\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.3459 - accuracy: 0.5131 - val_loss: 1.2497 - val_accuracy: 0.5512\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 12ms/step - loss: 1.2101 - accuracy: 0.5668 - val_loss: 1.0865 - val_accuracy: 0.6153\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1064 - accuracy: 0.6092 - val_loss: 1.0240 - val_accuracy: 0.6397\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0395 - accuracy: 0.6341 - val_loss: 0.9633 - val_accuracy: 0.6637\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9747 - accuracy: 0.6558 - val_loss: 0.8961 - val_accuracy: 0.6887\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9283 - accuracy: 0.6724 - val_loss: 0.9042 - val_accuracy: 0.6882\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8919 - accuracy: 0.6849 - val_loss: 0.8283 - val_accuracy: 0.7136\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8465 - accuracy: 0.7011 - val_loss: 0.8134 - val_accuracy: 0.7179\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8166 - accuracy: 0.7101 - val_loss: 0.8114 - val_accuracy: 0.7237\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7864 - accuracy: 0.7221 - val_loss: 0.7922 - val_accuracy: 0.7219\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7613 - accuracy: 0.7298 - val_loss: 0.7981 - val_accuracy: 0.7316\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7396 - accuracy: 0.7369 - val_loss: 0.7679 - val_accuracy: 0.7382\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7186 - accuracy: 0.7449 - val_loss: 0.7450 - val_accuracy: 0.7431\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6914 - accuracy: 0.7557 - val_loss: 0.7241 - val_accuracy: 0.7515\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6711 - accuracy: 0.7607 - val_loss: 0.7140 - val_accuracy: 0.7550\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6685 - accuracy: 0.7629 - val_loss: 0.7040 - val_accuracy: 0.7570\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6436 - accuracy: 0.7703 - val_loss: 0.7369 - val_accuracy: 0.7504\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6336 - accuracy: 0.7769 - val_loss: 0.7026 - val_accuracy: 0.7629\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6143 - accuracy: 0.7809 - val_loss: 0.7082 - val_accuracy: 0.7591\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6042 - accuracy: 0.7858 - val_loss: 0.7002 - val_accuracy: 0.7604\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5823 - accuracy: 0.7924 - val_loss: 0.7382 - val_accuracy: 0.7468\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5821 - accuracy: 0.7931 - val_loss: 0.6840 - val_accuracy: 0.7666\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5701 - accuracy: 0.7973 - val_loss: 0.7308 - val_accuracy: 0.7493\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5551 - accuracy: 0.8035 - val_loss: 0.6861 - val_accuracy: 0.7676\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5464 - accuracy: 0.8049 - val_loss: 0.7117 - val_accuracy: 0.7623\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5449 - accuracy: 0.8067 - val_loss: 0.7283 - val_accuracy: 0.7560\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5257 - accuracy: 0.8122 - val_loss: 0.7042 - val_accuracy: 0.7594\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5283 - accuracy: 0.8117 - val_loss: 0.6699 - val_accuracy: 0.7769\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5162 - accuracy: 0.8159 - val_loss: 0.6976 - val_accuracy: 0.7663\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5016 - accuracy: 0.8206 - val_loss: 0.6829 - val_accuracy: 0.7710\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4985 - accuracy: 0.8218 - val_loss: 0.6941 - val_accuracy: 0.7643\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4913 - accuracy: 0.8245 - val_loss: 0.6792 - val_accuracy: 0.7765\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4883 - accuracy: 0.8276 - val_loss: 0.6642 - val_accuracy: 0.7780\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4711 - accuracy: 0.8301 - val_loss: 0.6948 - val_accuracy: 0.7714\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4691 - accuracy: 0.8323 - val_loss: 0.6705 - val_accuracy: 0.7768\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4630 - accuracy: 0.8364 - val_loss: 0.6915 - val_accuracy: 0.7747\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4657 - accuracy: 0.8340 - val_loss: 0.7114 - val_accuracy: 0.7665\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4533 - accuracy: 0.8380 - val_loss: 0.6942 - val_accuracy: 0.7688\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4506 - accuracy: 0.8384 - val_loss: 0.6920 - val_accuracy: 0.7693\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4387 - accuracy: 0.8418 - val_loss: 0.7121 - val_accuracy: 0.7713\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4445 - accuracy: 0.8410 - val_loss: 0.6834 - val_accuracy: 0.7770\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4376 - accuracy: 0.8439 - val_loss: 0.6710 - val_accuracy: 0.7809\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4310 - accuracy: 0.8454 - val_loss: 0.6855 - val_accuracy: 0.7727\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4270 - accuracy: 0.8470 - val_loss: 0.6886 - val_accuracy: 0.7817\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4244 - accuracy: 0.8465 - val_loss: 0.6885 - val_accuracy: 0.7777\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4103 - accuracy: 0.8525 - val_loss: 0.6974 - val_accuracy: 0.7747\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4126 - accuracy: 0.8517 - val_loss: 0.7183 - val_accuracy: 0.7709\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4166 - accuracy: 0.8505 - val_loss: 0.6914 - val_accuracy: 0.7770\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4016 - accuracy: 0.8548 - val_loss: 0.6951 - val_accuracy: 0.7762\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3934 - accuracy: 0.8594 - val_loss: 0.7053 - val_accuracy: 0.7732\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4000 - accuracy: 0.8552 - val_loss: 0.7178 - val_accuracy: 0.7699\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3939 - accuracy: 0.8592 - val_loss: 0.6978 - val_accuracy: 0.7772\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3866 - accuracy: 0.8595 - val_loss: 0.6999 - val_accuracy: 0.7807\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3854 - accuracy: 0.8618 - val_loss: 0.6954 - val_accuracy: 0.7785\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3805 - accuracy: 0.8651 - val_loss: 0.7065 - val_accuracy: 0.7789\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.3779 - accuracy: 0.8657 - val_loss: 0.6995 - val_accuracy: 0.7818\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3858 - accuracy: 0.8619 - val_loss: 0.6860 - val_accuracy: 0.7817\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3780 - accuracy: 0.8652 - val_loss: 0.6969 - val_accuracy: 0.7752\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3743 - accuracy: 0.8658 - val_loss: 0.6976 - val_accuracy: 0.7799\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3704 - accuracy: 0.8682 - val_loss: 0.6985 - val_accuracy: 0.7776\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3684 - accuracy: 0.8681 - val_loss: 0.7024 - val_accuracy: 0.7800\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3666 - accuracy: 0.8700 - val_loss: 0.7027 - val_accuracy: 0.7803\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3581 - accuracy: 0.8716 - val_loss: 0.7059 - val_accuracy: 0.7743\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3627 - accuracy: 0.8710 - val_loss: 0.6900 - val_accuracy: 0.7821\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3486 - accuracy: 0.8758 - val_loss: 0.7111 - val_accuracy: 0.7803\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3485 - accuracy: 0.8755 - val_loss: 0.7282 - val_accuracy: 0.7757\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3505 - accuracy: 0.8739 - val_loss: 0.7049 - val_accuracy: 0.7786\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3547 - accuracy: 0.8728 - val_loss: 0.7312 - val_accuracy: 0.7746\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3445 - accuracy: 0.8764 - val_loss: 0.7267 - val_accuracy: 0.7727\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3463 - accuracy: 0.8753 - val_loss: 0.7322 - val_accuracy: 0.7794\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3418 - accuracy: 0.8778 - val_loss: 0.7068 - val_accuracy: 0.7839\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3395 - accuracy: 0.8776 - val_loss: 0.7365 - val_accuracy: 0.7754\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3446 - accuracy: 0.8763 - val_loss: 0.7165 - val_accuracy: 0.7781\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.3358 - accuracy: 0.8800 - val_loss: 0.7281 - val_accuracy: 0.7819\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3397 - accuracy: 0.8782 - val_loss: 0.7412 - val_accuracy: 0.7802\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3406 - accuracy: 0.8776 - val_loss: 0.7383 - val_accuracy: 0.7822\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3305 - accuracy: 0.8820 - val_loss: 0.7159 - val_accuracy: 0.7840\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3324 - accuracy: 0.8810 - val_loss: 0.7081 - val_accuracy: 0.7822\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3276 - accuracy: 0.8823 - val_loss: 0.7134 - val_accuracy: 0.7858\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3269 - accuracy: 0.8832 - val_loss: 0.7263 - val_accuracy: 0.7813\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3184 - accuracy: 0.8857 - val_loss: 0.7187 - val_accuracy: 0.7837\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3217 - accuracy: 0.8850 - val_loss: 0.7242 - val_accuracy: 0.7827\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3191 - accuracy: 0.8877 - val_loss: 0.7328 - val_accuracy: 0.7845\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3252 - accuracy: 0.8829 - val_loss: 0.7414 - val_accuracy: 0.7807\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3156 - accuracy: 0.8873 - val_loss: 0.7321 - val_accuracy: 0.7844\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3178 - accuracy: 0.8858 - val_loss: 0.7328 - val_accuracy: 0.7824\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3136 - accuracy: 0.8871 - val_loss: 0.7515 - val_accuracy: 0.7789\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3241 - accuracy: 0.8837 - val_loss: 0.7503 - val_accuracy: 0.7779\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3112 - accuracy: 0.8875 - val_loss: 0.7399 - val_accuracy: 0.7811\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3123 - accuracy: 0.8874 - val_loss: 0.7588 - val_accuracy: 0.7783\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3084 - accuracy: 0.8903 - val_loss: 0.7251 - val_accuracy: 0.7868\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3158 - accuracy: 0.8882 - val_loss: 0.7328 - val_accuracy: 0.7792\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3056 - accuracy: 0.8902 - val_loss: 0.7622 - val_accuracy: 0.7719\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3046 - accuracy: 0.8911 - val_loss: 0.7309 - val_accuracy: 0.7823\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3037 - accuracy: 0.8916 - val_loss: 0.7386 - val_accuracy: 0.7816\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3116 - accuracy: 0.8894 - val_loss: 0.7308 - val_accuracy: 0.7847\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3015 - accuracy: 0.8913 - val_loss: 0.7426 - val_accuracy: 0.7818\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3092 - accuracy: 0.8899 - val_loss: 0.7429 - val_accuracy: 0.7842\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3052 - accuracy: 0.8908 - val_loss: 0.7572 - val_accuracy: 0.7815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qGl3H8jSD1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aecff921-f357-4fce-db62-11f69a90978a"
      },
      "source": [
        "learning_rate = 0.001\n",
        "opt = keras.optimizers.Adam(lr = learning_rate)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "no_classes = 10\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "val_split = 0.2\n",
        "Dropout_Factor = 0.25\n",
        "img_width, img_height, num_channels = 32,32,3\n",
        "input_shape = (img_width, img_height, num_channels)\n",
        "\n",
        "Dropout_model = Sequential()\n",
        "Dropout_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,kernel_initializer = 'random_normal'))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Dropout(0.25))\n",
        "Dropout_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_initializer = 'random_normal',kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "Dropout_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "Dropout_model.add(Dropout(0.25))\n",
        "Dropout_model.add(Flatten())\n",
        "Dropout_model.add(Dense(256, activation='relu'))\n",
        "Dropout_model.add(Dense(128, activation='relu'))\n",
        "Dropout_model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "logdir = \"logs/dropouts\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "Dropout_model.compile(optimizer=opt,loss=loss_fn,metrics=[\"accuracy\"])\n",
        "Dropout_regularizers_history = Dropout_model.fit(data,batch_size = batch_size,epochs = 100,validation_data = (test_data),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/391 [..............................] - ETA: 17s - loss: 2.3703 - accuracy: 0.0742WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0776s). Check your callbacks.\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7520 - accuracy: 0.3634 - val_loss: 1.4672 - val_accuracy: 0.4758\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3953 - accuracy: 0.5096 - val_loss: 1.2635 - val_accuracy: 0.5630\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2467 - accuracy: 0.5709 - val_loss: 1.1460 - val_accuracy: 0.6178\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1550 - accuracy: 0.6027 - val_loss: 1.0756 - val_accuracy: 0.6421\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0778 - accuracy: 0.6372 - val_loss: 1.0195 - val_accuracy: 0.6594\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0272 - accuracy: 0.6549 - val_loss: 0.9474 - val_accuracy: 0.6930\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9725 - accuracy: 0.6748 - val_loss: 0.9212 - val_accuracy: 0.6998\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9411 - accuracy: 0.6878 - val_loss: 0.8842 - val_accuracy: 0.7141\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9069 - accuracy: 0.7027 - val_loss: 0.8506 - val_accuracy: 0.7221\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8786 - accuracy: 0.7115 - val_loss: 0.8829 - val_accuracy: 0.7150\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8477 - accuracy: 0.7239 - val_loss: 0.8347 - val_accuracy: 0.7353\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8408 - accuracy: 0.7262 - val_loss: 0.8182 - val_accuracy: 0.7442\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8145 - accuracy: 0.7354 - val_loss: 0.8285 - val_accuracy: 0.7361\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7944 - accuracy: 0.7412 - val_loss: 0.7880 - val_accuracy: 0.7512\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7864 - accuracy: 0.7465 - val_loss: 0.8076 - val_accuracy: 0.7463\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7660 - accuracy: 0.7560 - val_loss: 0.8045 - val_accuracy: 0.7479\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7590 - accuracy: 0.7578 - val_loss: 0.7687 - val_accuracy: 0.7619\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7390 - accuracy: 0.7662 - val_loss: 0.8030 - val_accuracy: 0.7492\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7305 - accuracy: 0.7677 - val_loss: 0.7598 - val_accuracy: 0.7636\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7215 - accuracy: 0.7712 - val_loss: 0.7771 - val_accuracy: 0.7563\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7054 - accuracy: 0.7786 - val_loss: 0.7528 - val_accuracy: 0.7686\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6939 - accuracy: 0.7828 - val_loss: 0.7688 - val_accuracy: 0.7636\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6824 - accuracy: 0.7860 - val_loss: 0.7476 - val_accuracy: 0.7683\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6785 - accuracy: 0.7881 - val_loss: 0.7606 - val_accuracy: 0.7670\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6726 - accuracy: 0.7911 - val_loss: 0.7882 - val_accuracy: 0.7598\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6607 - accuracy: 0.7943 - val_loss: 0.7810 - val_accuracy: 0.7657\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6526 - accuracy: 0.7976 - val_loss: 0.7877 - val_accuracy: 0.7571\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6436 - accuracy: 0.7996 - val_loss: 0.7515 - val_accuracy: 0.7706\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6355 - accuracy: 0.8048 - val_loss: 0.7612 - val_accuracy: 0.7685\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6285 - accuracy: 0.8071 - val_loss: 0.7232 - val_accuracy: 0.7797\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6255 - accuracy: 0.8065 - val_loss: 0.7339 - val_accuracy: 0.7774\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6199 - accuracy: 0.8101 - val_loss: 0.7538 - val_accuracy: 0.7706\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6093 - accuracy: 0.8148 - val_loss: 0.7415 - val_accuracy: 0.7792\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6019 - accuracy: 0.8187 - val_loss: 0.7346 - val_accuracy: 0.7783\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5948 - accuracy: 0.8189 - val_loss: 0.7409 - val_accuracy: 0.7740\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5937 - accuracy: 0.8206 - val_loss: 0.7289 - val_accuracy: 0.7845\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5885 - accuracy: 0.8226 - val_loss: 0.7337 - val_accuracy: 0.7767\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5838 - accuracy: 0.8243 - val_loss: 0.7493 - val_accuracy: 0.7792\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5819 - accuracy: 0.8243 - val_loss: 0.7310 - val_accuracy: 0.7839\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5769 - accuracy: 0.8269 - val_loss: 0.7495 - val_accuracy: 0.7747\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5697 - accuracy: 0.8281 - val_loss: 0.7347 - val_accuracy: 0.7817\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5734 - accuracy: 0.8278 - val_loss: 0.7507 - val_accuracy: 0.7768\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5574 - accuracy: 0.8340 - val_loss: 0.7457 - val_accuracy: 0.7794\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5598 - accuracy: 0.8339 - val_loss: 0.7493 - val_accuracy: 0.7783\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5605 - accuracy: 0.8316 - val_loss: 0.7528 - val_accuracy: 0.7780\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5500 - accuracy: 0.8363 - val_loss: 0.7559 - val_accuracy: 0.7752\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5497 - accuracy: 0.8380 - val_loss: 0.7359 - val_accuracy: 0.7880\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5445 - accuracy: 0.8384 - val_loss: 0.7531 - val_accuracy: 0.7787\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5488 - accuracy: 0.8372 - val_loss: 0.7650 - val_accuracy: 0.7759\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5386 - accuracy: 0.8429 - val_loss: 0.7593 - val_accuracy: 0.7782\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5397 - accuracy: 0.8410 - val_loss: 0.7534 - val_accuracy: 0.7826\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5319 - accuracy: 0.8447 - val_loss: 0.7402 - val_accuracy: 0.7835\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5282 - accuracy: 0.8462 - val_loss: 0.7579 - val_accuracy: 0.7789\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5306 - accuracy: 0.8460 - val_loss: 0.7504 - val_accuracy: 0.7786\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5263 - accuracy: 0.8483 - val_loss: 0.7440 - val_accuracy: 0.7829\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5191 - accuracy: 0.8485 - val_loss: 0.7623 - val_accuracy: 0.7781\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5170 - accuracy: 0.8512 - val_loss: 0.7873 - val_accuracy: 0.7708\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5137 - accuracy: 0.8519 - val_loss: 0.7524 - val_accuracy: 0.7903\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5135 - accuracy: 0.8505 - val_loss: 0.7577 - val_accuracy: 0.7800\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5073 - accuracy: 0.8545 - val_loss: 0.7464 - val_accuracy: 0.7855\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5116 - accuracy: 0.8512 - val_loss: 0.7469 - val_accuracy: 0.7898\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5117 - accuracy: 0.8506 - val_loss: 0.7612 - val_accuracy: 0.7869\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5018 - accuracy: 0.8569 - val_loss: 0.7590 - val_accuracy: 0.7835\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4970 - accuracy: 0.8563 - val_loss: 0.7404 - val_accuracy: 0.7886\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5058 - accuracy: 0.8542 - val_loss: 0.7742 - val_accuracy: 0.7787\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5012 - accuracy: 0.8549 - val_loss: 0.7734 - val_accuracy: 0.7842\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4971 - accuracy: 0.8577 - val_loss: 0.7444 - val_accuracy: 0.7907\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4967 - accuracy: 0.8599 - val_loss: 0.7738 - val_accuracy: 0.7806\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4884 - accuracy: 0.8616 - val_loss: 0.7558 - val_accuracy: 0.7846\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4907 - accuracy: 0.8592 - val_loss: 0.7603 - val_accuracy: 0.7846\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4909 - accuracy: 0.8595 - val_loss: 0.7548 - val_accuracy: 0.7877\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4884 - accuracy: 0.8612 - val_loss: 0.7549 - val_accuracy: 0.7880\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4772 - accuracy: 0.8666 - val_loss: 0.7730 - val_accuracy: 0.7832\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4809 - accuracy: 0.8636 - val_loss: 0.7676 - val_accuracy: 0.7873\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4839 - accuracy: 0.8625 - val_loss: 0.7819 - val_accuracy: 0.7829\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4778 - accuracy: 0.8640 - val_loss: 0.7691 - val_accuracy: 0.7849\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4823 - accuracy: 0.8644 - val_loss: 0.7658 - val_accuracy: 0.7874\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4742 - accuracy: 0.8667 - val_loss: 0.7666 - val_accuracy: 0.7904\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4753 - accuracy: 0.8670 - val_loss: 0.7627 - val_accuracy: 0.7922\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4655 - accuracy: 0.8700 - val_loss: 0.8063 - val_accuracy: 0.7783\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8659 - val_loss: 0.8003 - val_accuracy: 0.7789\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4693 - accuracy: 0.8692 - val_loss: 0.7562 - val_accuracy: 0.7901\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4689 - accuracy: 0.8686 - val_loss: 0.7753 - val_accuracy: 0.7842\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4655 - accuracy: 0.8695 - val_loss: 0.7895 - val_accuracy: 0.7832\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4683 - accuracy: 0.8692 - val_loss: 0.7633 - val_accuracy: 0.7863\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4608 - accuracy: 0.8717 - val_loss: 0.7802 - val_accuracy: 0.7831\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8705 - val_loss: 0.7564 - val_accuracy: 0.7900\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4648 - accuracy: 0.8704 - val_loss: 0.7949 - val_accuracy: 0.7846\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4608 - accuracy: 0.8728 - val_loss: 0.7690 - val_accuracy: 0.7894\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4567 - accuracy: 0.8751 - val_loss: 0.7867 - val_accuracy: 0.7857\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4570 - accuracy: 0.8740 - val_loss: 0.7736 - val_accuracy: 0.7899\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4570 - accuracy: 0.8747 - val_loss: 0.7724 - val_accuracy: 0.7900\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4590 - accuracy: 0.8740 - val_loss: 0.7690 - val_accuracy: 0.7861\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4584 - accuracy: 0.8728 - val_loss: 0.8025 - val_accuracy: 0.7793\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4580 - accuracy: 0.8737 - val_loss: 0.7749 - val_accuracy: 0.7866\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4485 - accuracy: 0.8759 - val_loss: 0.7938 - val_accuracy: 0.7848\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4488 - accuracy: 0.8747 - val_loss: 0.7567 - val_accuracy: 0.7923\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4515 - accuracy: 0.8763 - val_loss: 0.7896 - val_accuracy: 0.7838\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4550 - accuracy: 0.8723 - val_loss: 0.8053 - val_accuracy: 0.7760\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4455 - accuracy: 0.8769 - val_loss: 0.7840 - val_accuracy: 0.7857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9xxOgwCU_70",
        "colab_type": "text"
      },
      "source": [
        "## L1 L2 Regularization\n",
        "\n",
        "The l1 l2 regularizers are applied to all the convolution kernels. A maximum Validation accuracy of 71.8% is obtained. The model converged at 17th epoch after which the the validation accuracy varied around 71-72%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWhgcKnaGRr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e12e4d2a-c3c6-4251-d90d-13dbf754ad2a"
      },
      "source": [
        "plt.plot(regulaizer_history.history['accuracy'])\n",
        "plt.plot(regulaizer_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MIb5hyPV3fY",
        "colab_type": "text"
      },
      "source": [
        "## Dropout and regularization\n",
        "\n",
        "This gave comparitively better result. The model could achieve a maximum validation accuracy of 79% and it stopped converging around 25th epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLRYvDZAJh81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dc86606d-9bda-4e24-e26d-1a3f58afb758"
      },
      "source": [
        "plt.plot(Dropout_history.history['accuracy'])\n",
        "plt.plot(Dropout_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KfinQdUJsvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}